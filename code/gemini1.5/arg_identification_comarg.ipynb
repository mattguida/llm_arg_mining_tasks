{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from huggingface_hub import login\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import accelerate\n",
    "import jsonlines\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os, csv, re\n",
    "import openai\n",
    "import inspect\n",
    "import typing_extensions as typing\n",
    "\n",
    "\n",
    "from modelsmith import Forge, VertexAIGenerativeModel\n",
    "\n",
    "from typing import List\n",
    "from pydantic import ValidationError, BaseModel, Field\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import jsonlines as jl\n",
    "import json\n",
    "import time\n",
    "from tqdm import tqdm\n",
    " \n",
    "\n",
    "import google.generativeai as genai\n",
    "from google.generativeai.types import RequestOptions\n",
    "from google.api_core import retry\n",
    "from google.auth import default, transport\n",
    "from modelsmith import Forge, VertexAIGenerativeModel\n",
    "from vertexai.generative_models import GenerationConfig, GenerativeModel, Part\n",
    "from dotenv import load_dotenv\n",
    "import vertexai\n",
    "\n",
    "load_dotenv('/Users/guida/llm_argument_tasks/.env')\n",
    "\n",
    "api_key = os.environ.get('OPENAI_API_KEY')\n",
    "PROJECT_ID = os.environ.get('GEMINI_PROJECT_ID')\n",
    "LOCATION = \"us-central1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "forge = Forge(\n",
    "    model=VertexAIGenerativeModel(\"gemini-1.5-flash\"), response_model=list[str]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vertexai\n",
    "\n",
    "vertexai.init(\n",
    "        project=\"leas-team\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArgumentClassification(typing.TypedDict):\n",
    "    id: str\n",
    "    label: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_text(id: str, comment_text: str, argument: str) -> dict:\n",
    "    model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "    \n",
    "    safety_settings = {\n",
    "        \"HARM_CATEGORY_HARASSMENT\": \"block_none\",\n",
    "        \"HARM_CATEGORY_HATE_SPEECH\": \"block_none\",\n",
    "        \"HARM_CATEGORY_SEXUALLY_EXPLICIT\": \"block_none\",\n",
    "        \"HARM_CATEGORY_DANGEROUS_CONTENT\": \"block_none\"\n",
    "    }\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Analyze the given comment about gay marriage in relation to gay marriage. Your need to:\n",
    "    Identify if the comment makes use the given argument. If it does, assign the label 1. If it does not, assign the label 0.\n",
    "    Do NOT use any other label.\n",
    "    Do NOT include the comment or the argument in the response.\n",
    "    \n",
    "    The argument to analyze is: {argument}\n",
    "    \n",
    "    Provide your response in the following JSON format:\n",
    "    \n",
    "    {{\n",
    "        \"id\": \"{id}\",\n",
    "        \"label\": \"the label for the use of the argument in the comment\"\n",
    "    }}\n",
    "    \n",
    "    Analyze the following comment in relation to the given argument:\n",
    "    {comment_text}\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = model.generate_content(\n",
    "            prompt,\n",
    "            generation_config=genai.types.GenerationConfig(\n",
    "                response_mime_type=\"application/json\",\n",
    "                response_schema=ArgumentClassification,\n",
    "                temperature=0,\n",
    "                top_p=1,\n",
    "            ),\n",
    "            safety_settings=safety_settings\n",
    "        )\n",
    "        \n",
    "        return response.text\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred for comment: {comment_text[:30]}... - Error: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing comments:   0%|          | 0/1386 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing comments: 100%|██████████| 1386/1386 [10:10<00:00,  2.27it/s]\n"
     ]
    }
   ],
   "source": [
    "gm = pd.read_csv('../../clean_data/GM_all_arguments.csv')\n",
    "\n",
    "def process_comments_with_arguments(df: pd.DataFrame, output_file: str):\n",
    "    with jsonlines.open(output_file, mode='a') as writer:\n",
    "        for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing comments\"):\n",
    "            comment_id = row['id']\n",
    "            comment_text = row['comment_text']\n",
    "            argument_text = row['argument_text']\n",
    "            try:\n",
    "                gemini_response = classify_text(comment_id, comment_text, argument_text)\n",
    "                classification = json.loads(gemini_response)\n",
    "                writer.write(classification)\n",
    "\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"JSONDecodeError for comment: {comment_text[:50]}... - Error: {e}\")\n",
    "                continue\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"An unexpected error occurred for comment: {comment_text[:50]}... - Error: {e}\")\n",
    "                continue\n",
    "\n",
    "output_file = 'comarg_gm_argument_identification_gemini.jsonl'\n",
    "process_comments_with_arguments(gm, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_text_ugip(id: str, comment_text: str, argument: str) -> dict:\n",
    "    model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "    \n",
    "    safety_settings = {\n",
    "        \"HARM_CATEGORY_HARASSMENT\": \"block_none\",\n",
    "        \"HARM_CATEGORY_HATE_SPEECH\": \"block_none\",\n",
    "        \"HARM_CATEGORY_SEXUALLY_EXPLICIT\": \"block_none\",\n",
    "        \"HARM_CATEGORY_DANGEROUS_CONTENT\": \"block_none\"\n",
    "    }\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Analyze the given comment in relation to a specific argument about whether \"Under God\" should appear in the US Pledge of Allegiance. You need to:\n",
    "    Identify if the comment makes use the given argument. If it does, assign the label 1. If it does not, assign the label 0.\n",
    "    Do NOT use any other label.\n",
    "    Do NOT include the comment or the argument in the response.\n",
    "    \n",
    "    The argument to analyze is: {argument}\n",
    "    \n",
    "    Provide your response in the following JSON format:\n",
    "    \n",
    "    {{\n",
    "        \"id\": \"{id}\",\n",
    "        \"label\": \"the label for the use of the argument in the comment\"\n",
    "    }}\n",
    "    \n",
    "    Analyze the following comment in relation to the given argument:\n",
    "    {comment_text}\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = model.generate_content(\n",
    "            prompt,\n",
    "            generation_config=genai.types.GenerationConfig(\n",
    "                response_mime_type=\"application/json\",\n",
    "                response_schema=ArgumentClassification,\n",
    "                temperature=0,\n",
    "                top_p=1,\n",
    "            ),\n",
    "            safety_settings=safety_settings\n",
    "        )\n",
    "        \n",
    "        return response.text\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred for comment: {comment_text[:30]}... - Error: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing comments: 100%|██████████| 2100/2100 [16:39<00:00,  2.10it/s]\n"
     ]
    }
   ],
   "source": [
    "ugip = pd.read_csv('../../clean_data/UGIP_all_arguments.csv')\n",
    "\n",
    "def process_comments_with_arguments(df: pd.DataFrame, output_file: str):\n",
    "    with jsonlines.open(output_file, mode='a') as writer:\n",
    "        for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing comments\"):\n",
    "            comment_id = row['id']\n",
    "            comment_text = row['comment_text']\n",
    "            argument_text = row['argument_text']\n",
    "            try:\n",
    "                gemini_response = classify_text_ugip(comment_id, comment_text, argument_text)\n",
    "                classification = json.loads(gemini_response)\n",
    "                writer.write(classification)\n",
    "\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"JSONDecodeError for comment: {comment_text[:50]}... - Error: {e}\")\n",
    "                continue\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"An unexpected error occurred for comment: {comment_text[:50]}... - Error: {e}\")\n",
    "                continue\n",
    "\n",
    "output_file = 'comarg_ugip_argument_identification_gemini.jsonl'\n",
    "process_comments_with_arguments(ugip, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
