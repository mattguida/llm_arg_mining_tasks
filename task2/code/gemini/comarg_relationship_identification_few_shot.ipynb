{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from random import sample\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from huggingface_hub import login\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import accelerate\n",
    "import jsonlines\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os, csv, re\n",
    "import openai\n",
    "import inspect\n",
    "import typing_extensions as typing\n",
    "\n",
    "\n",
    "from modelsmith import Forge, VertexAIGenerativeModel\n",
    "\n",
    "from typing import List\n",
    "from pydantic import ValidationError, BaseModel, Field\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import jsonlines as jl\n",
    "import json\n",
    "import time\n",
    "from tqdm import tqdm\n",
    " \n",
    "\n",
    "import google.generativeai as genai\n",
    "from google.generativeai.types import RequestOptions\n",
    "from google.api_core import retry\n",
    "from google.auth import default, transport\n",
    "from modelsmith import Forge, VertexAIGenerativeModel\n",
    "from vertexai.generative_models import GenerationConfig, GenerativeModel, Part\n",
    "from dotenv import load_dotenv\n",
    "import vertexai\n",
    "\n",
    "load_dotenv('/Users/guida/llm_argument_tasks/.env')\n",
    "\n",
    "api_key = os.environ.get('OPENAI_API_KEY')\n",
    "PROJECT_ID = os.environ.get('GEMINI_PROJECT_ID')\n",
    "LOCATION = \"us-central1\"\n",
    "\n",
    "vertexai.init(\n",
    "        project=\"leas-team\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelationClassification(typing.TypedDict):\n",
    "    id: str \n",
    "    label: int "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_fewshot_samples_2ways(samples_file, n):\n",
    "    df = pd.read_csv(samples_file)\n",
    "    ids = df['id'].to_list()\n",
    "    sampled = sample(ids, n)\n",
    "    print(sampled)\n",
    "    df = df[df['id'].isin(sampled)]\n",
    "    comment = df.iloc[0]['comment_text']\n",
    "    output = f\"Comment: {comment}\\n The comment attacks (1), or supports (5) the following argument(s):\\n\"\n",
    "    #print(output)\n",
    "    for i, row in df.iterrows():\n",
    "        argument = row['argument_text']\n",
    "        output = f\"{output} Argument {i}: {argument}\\n\"\n",
    "        label = row['label']\n",
    "        print(label)\n",
    "        if label == 2:\n",
    "            label = 1\n",
    "            print(label)\n",
    "        if label == 4:\n",
    "            label = 5\n",
    "            print(label)\n",
    "        output = f\"{output} Label: {label}\\n\\n\"\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_fewshot_samples_5ways(samples_file, n):\n",
    "    df = pd.read_csv(samples_file)\n",
    "    ids = df['id'].to_list()\n",
    "    sampled = sample(ids, n)\n",
    "    print(sampled)\n",
    "    df = df[df['id'].isin(sampled)]\n",
    "    comment = df.iloc[0]['comment_text']\n",
    "    output = f\"Comment: {comment}\\n The comment explicitly attacks (1), implicitly attacks (2), implicitly supports (4), or explicitly supports (5) the following argument(s):\\n\"\n",
    "    #print(output)\n",
    "    for i, row in df.iterrows():\n",
    "        argument = row['argument_text']\n",
    "        output = f\"{output} Argument {i}: {argument}\\n\"\n",
    "        label = row['label']\n",
    "        output = f\"{output} Label: {label}\\n\\n\"\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_text_2ways(id: str, comment_text: str, argument: str, topic: str, samples: str) -> dict:\n",
    "        model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "        \n",
    "        safety_settings = {\n",
    "            \"HARM_CATEGORY_HARASSMENT\": \"block_none\",\n",
    "            \"HARM_CATEGORY_HATE_SPEECH\": \"block_none\",\n",
    "            \"HARM_CATEGORY_SEXUALLY_EXPLICIT\": \"block_none\",\n",
    "            \"HARM_CATEGORY_DANGEROUS_CONTENT\": \"block_none\"\n",
    "        }\n",
    "        prompt=f\"\"\"\n",
    "            Analyze the given comment about {topic} in relation to a specific argument. You need to:\n",
    "            Identify if the comment makes use of the given argument. Assign the following labels:\n",
    "            - 1 if the comment attacks the argument.\n",
    "            - 5 if the comment supports the argument.\n",
    "            Do NOT use any other label.\n",
    "            Do NOT include the comment or the argument in the response.\n",
    "\n",
    "            Some examples:\n",
    "            {samples}\n",
    "            \n",
    "            The argument to analyze is: {argument}\n",
    "            \n",
    "            Provide your response in the following JSON format:\n",
    "            \n",
    "            {{\n",
    "                \"id\": \"{id}\",\n",
    "                \"label\": \"the label for the use of the argument in the comment\"\n",
    "            }}\n",
    "            \n",
    "            Analyze the following comment in relation to the given argument:\n",
    "            {comment_text},\n",
    "            \"\"\"\n",
    "        response = model.generate_content(\n",
    "                    prompt,\n",
    "                    generation_config=genai.types.GenerationConfig(\n",
    "                        response_mime_type=\"application/json\",\n",
    "                        response_schema=RelationClassification,\n",
    "                        temperature=0,\n",
    "                        top_p=1,\n",
    "                    ),\n",
    "                    safety_settings=safety_settings\n",
    "        )\n",
    "                \n",
    "        return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_text_5ways(id: str, comment_text: str, argument: str, topic: str, samples: str) -> dict:\n",
    "        model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "        \n",
    "        safety_settings = {\n",
    "            \"HARM_CATEGORY_HARASSMENT\": \"block_none\",\n",
    "            \"HARM_CATEGORY_HATE_SPEECH\": \"block_none\",\n",
    "            \"HARM_CATEGORY_SEXUALLY_EXPLICIT\": \"block_none\",\n",
    "            \"HARM_CATEGORY_DANGEROUS_CONTENT\": \"block_none\"\n",
    "        }\n",
    "        prompt=f\"\"\"\n",
    "            Analyze the given comment about {topic} in relation to a specific argument. You need to:\n",
    "            Identify if the comment makes use of the given argument. Assign the following labels:\n",
    "            - 1 if the comment attacks the argument explicitly.\n",
    "            - 2 if the comment attacks the argument implicitly/vaguely.\n",
    "            - 4 if the comment supports the argument implicitly/vaguely.\n",
    "            - 5 if the comment supports the argument explicitly.\n",
    "            Do NOT use any other label.\n",
    "            Do NOT include the comment or the argument in the response.\n",
    "\n",
    "            Some examples:\n",
    "            {samples}\n",
    "            \n",
    "            The argument to analyze is: {argument}\n",
    "            \n",
    "            Provide your response in the following JSON format:\n",
    "            \n",
    "            {{\n",
    "                \"id\": \"{id}\",\n",
    "                \"label\": \"the label for the use of the argument in the comment\"\n",
    "            }}\n",
    "            \n",
    "            Analyze the following comment in relation to the given argument:\n",
    "            {comment_text},\n",
    "            \"\"\"\n",
    "        response = model.generate_content(\n",
    "                    prompt,\n",
    "                    generation_config=genai.types.GenerationConfig(\n",
    "                        response_mime_type=\"application/json\",\n",
    "                        response_schema=RelationClassification,\n",
    "                        temperature=0,\n",
    "                        top_p=1,\n",
    "                    ),\n",
    "                    safety_settings=safety_settings\n",
    "        )\n",
    "                \n",
    "        return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_comments_with_arguments(df: pd.DataFrame, output_file: str, topic: str, samples: str, detailed = False):\n",
    "    with jsonlines.open(output_file, mode='a') as writer:\n",
    "        for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing comments\"):\n",
    "            comment_id = row['id']\n",
    "            comment_text = row['comment_text']\n",
    "            argument_text = row['argument_text']\n",
    "            if detailed == False:\n",
    "                model = classify_text_2ways\n",
    "            else:\n",
    "                model = classify_text_5ways\n",
    "            try:\n",
    "                gemini_response = model(comment_id, comment_text, argument_text, topic, samples)\n",
    "                classification = json.loads(gemini_response)\n",
    "                writer.write(classification)\n",
    "\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"JSONDecodeError for comment: {comment_text[:50]}... - Error: {e}\")\n",
    "                error_entry = {\"id\": comment_id, \"label\": 3}\n",
    "                writer.write(error_entry)\n",
    "                continue\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"An unexpected error occurred for comment: {comment_text[:50]}... - Error: {e}\")\n",
    "                error_entry = {\"id\": comment_id, \"label\": 3}\n",
    "                writer.write(error_entry)\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['175arg4']\n",
      "2\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing comments: 100%|██████████| 431/431 [03:16<00:00,  2.20it/s]\n"
     ]
    }
   ],
   "source": [
    "gm = pd.read_csv('/Users/guida/llm_argument_tasks/clean_data/GM_structured_main.csv')\n",
    "samples = prep_fewshot_samples_2ways('/Users/guida/llm_argument_tasks/clean_data/GM_structured_one_shot.csv', 1)\n",
    "process_comments_with_arguments(gm, 'comarg_gm_relation_identification2ways_gemini_1shot.jsonl', 'gay marriage', samples, detailed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['198arg5', '161arg4', '175arg4', '108arg2', '5arg5']\n",
      "1\n",
      "2\n",
      "1\n",
      "4\n",
      "5\n",
      "5\n",
      "4\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing comments: 100%|██████████| 431/431 [03:15<00:00,  2.20it/s]\n"
     ]
    }
   ],
   "source": [
    "gm = pd.read_csv('/Users/guida/llm_argument_tasks/clean_data/GM_structured_main.csv')\n",
    "samples = prep_fewshot_samples_2ways('/Users/guida/llm_argument_tasks/clean_data/GM_structured_shots.csv',5)\n",
    "process_comments_with_arguments(gm, 'comarg_gm_relation_identification2ways_gemini_5shot.jsonl', 'gay marriage', samples, detailed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['198arg5']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing comments: 100%|██████████| 431/431 [03:15<00:00,  2.20it/s]\n"
     ]
    }
   ],
   "source": [
    "gm = pd.read_csv('/Users/guida/llm_argument_tasks/clean_data/GM_structured_main.csv')\n",
    "samples = prep_fewshot_samples_5ways('/Users/guida/llm_argument_tasks/clean_data/GM_structured_one_shot.csv',1)\n",
    "process_comments_with_arguments(gm, 'comarg_gm_relation_identification5ways_gemini_1shot.jsonl', 'gay marriage', samples, detailed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['161arg4', '175arg4', '5arg5', '198arg5', '108arg2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing comments: 100%|██████████| 431/431 [03:15<00:00,  2.21it/s]\n"
     ]
    }
   ],
   "source": [
    "gm = pd.read_csv('/Users/guida/llm_argument_tasks/clean_data/GM_structured_main.csv')\n",
    "samples = prep_fewshot_samples_5ways('/Users/guida/llm_argument_tasks/clean_data/GM_structured_shots.csv',5)\n",
    "process_comments_with_arguments(gm, 'comarg_gm_relation_identification5ways_gemini_5shot.jsonl', 'gay marriage', samples, detailed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['414721831arg6']\n",
      "4\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing comments:   0%|          | 0/317 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing comments: 100%|██████████| 317/317 [02:36<00:00,  2.02it/s]\n"
     ]
    }
   ],
   "source": [
    "ugip = pd.read_csv('/Users/guida/llm_argument_tasks/clean_data/UGIP_structured_main.csv')\n",
    "samples = prep_fewshot_samples_2ways('/Users/guida/llm_argument_tasks/clean_data/UGIP_structured_one_shot.csv', 1)\n",
    "process_comments_with_arguments(ugip, 'comarg_ugip_relation_identification2ways_gemini_1shot.jsonl', 'whether \"Under God\" should appear in the US Pledge of Allegiance', samples, detailed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['414721831arg6', '414721757arg6', '414721738arg1', '414721922arg3', '414721727arg3']\n",
      "1\n",
      "2\n",
      "1\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing comments: 100%|██████████| 317/317 [02:37<00:00,  2.01it/s]\n"
     ]
    }
   ],
   "source": [
    "ugip = pd.read_csv('/Users/guida/llm_argument_tasks/clean_data/UGIP_structured_main.csv')\n",
    "samples = prep_fewshot_samples_2ways('/Users/guida/llm_argument_tasks/clean_data/UGIP_structured_shots.csv',5)\n",
    "process_comments_with_arguments(ugip, 'comarg_ugip_relation_identification2ways_gemini_5shot.jsonl', 'whether \"Under God\" should appear in the US Pledge of Allegiance', samples, detailed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['414721727arg3']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing comments:   0%|          | 0/317 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing comments: 100%|██████████| 317/317 [02:35<00:00,  2.04it/s]\n"
     ]
    }
   ],
   "source": [
    "ugip = pd.read_csv('/Users/guida/llm_argument_tasks/clean_data/UGIP_structured_main.csv')\n",
    "samples = prep_fewshot_samples_5ways('/Users/guida/llm_argument_tasks/clean_data/UGIP_structured_one_shot.csv',1)\n",
    "process_comments_with_arguments(ugip, 'comarg_ugip_relation_identification5ways_gemini_1shot.jsonl', 'whether \"Under God\" should appear in the US Pledge of Allegiance', samples, detailed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['414721727arg3', '414721922arg3', '414721738arg1', '414721757arg6', '414721831arg6']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing comments: 100%|██████████| 317/317 [02:37<00:00,  2.02it/s]\n"
     ]
    }
   ],
   "source": [
    "ugip = pd.read_csv('/Users/guida/llm_argument_tasks/clean_data/UGIP_structured_main.csv')\n",
    "samples = prep_fewshot_samples_5ways('/Users/guida/llm_argument_tasks/clean_data/UGIP_structured_shots.csv',5)\n",
    "process_comments_with_arguments(ugip, 'comarg_ugip_relation_identification5ways_gemini_5shot.jsonl', 'whether \"Under God\" should appear in the US Pledge of Allegiance', samples, detailed=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
