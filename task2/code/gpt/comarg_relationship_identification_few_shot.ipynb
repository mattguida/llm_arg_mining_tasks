{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "import pandas as pd\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from random import sample\n",
    "import jsonlines as jsonl\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('/Users/guida/llm_argument_tasks/.env')\n",
    "\n",
    "api_key = os.environ.get('OPENAI_API_KEY')\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelationClassification(BaseModel):\n",
    "    id: str = Field(description=\"The ID of the comment being analyzed\")    \n",
    "    label: int = Field(description=\"The label associated with the argument\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_fewshot_samples_2ways(samples_file, n):\n",
    "    df = pd.read_csv(samples_file)\n",
    "    ids = df['id'].to_list()\n",
    "    sampled = sample(ids, n)\n",
    "    print(sampled)\n",
    "    df = df[df['id'].isin(sampled)]\n",
    "    comment = df.iloc[0]['comment_text']\n",
    "    output = f\"Comment: {comment}\\n The comment attacks (1), or supports (5) the following argument(s):\\n\"\n",
    "    #print(output)\n",
    "    for i, row in df.iterrows():\n",
    "        argument = row['argument_text']\n",
    "        output = f\"{output} Argument {i}: {argument}\\n\"\n",
    "        label = row['label']\n",
    "        print(label)\n",
    "        if label == 2:\n",
    "            label = 1\n",
    "            print(label)\n",
    "        if label == 4:\n",
    "            label = 5\n",
    "            print(label)\n",
    "        output = f\"{output} Label: {label}\\n\\n\"\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_fewshot_samples_5ways(samples_file, n):\n",
    "    df = pd.read_csv(samples_file)\n",
    "    ids = df['id'].to_list()\n",
    "    sampled = sample(ids, n)\n",
    "    print(sampled)\n",
    "    df = df[df['id'].isin(sampled)]\n",
    "    comment = df.iloc[0]['comment_text']\n",
    "    output = f\"Comment: {comment}\\n The comment explicitly attacks (1), implicitly attacks (2), implicitly supports (4), or explicitly supports (5) the following argument(s):\\n\"\n",
    "    #print(output)\n",
    "    for i, row in df.iterrows():\n",
    "        argument = row['argument_text']\n",
    "        output = f\"{output} Argument {i}: {argument}\\n\"\n",
    "        label = row['label']\n",
    "        output = f\"{output} Label: {label}\\n\\n\"\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_text_2ways(id: str, comment_text: str, argument: str, topic: str, samples: str) -> dict:\n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model='gpt-4o-mini',\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": f\"\"\"\n",
    "            Analyze the given comment about {topic} in relation to a specific argument. You need to:\n",
    "            Identify if the comment makes use of the given argument. Assign the following labels:\n",
    "            - 1 if the comment attacks the argument.\n",
    "            - 5 if the comment supports the argument.\n",
    "            Do NOT use any other label.\n",
    "            Do NOT include the comment or the argument in the response.\n",
    "\n",
    "            Some examples:\n",
    "            {samples}\n",
    "            \n",
    "            The argument to analyze is: {argument}\n",
    "            \n",
    "            Provide your response in the following JSON format:\n",
    "            \n",
    "            {{\n",
    "                \"id\": \"{id}\",\n",
    "                \"label\": \"the label for the use of the argument in the comment\"\n",
    "            }}\n",
    "            \n",
    "            Analyze the following comment in relation to the given argument:\n",
    "            \"\"\"},\n",
    "            {\"role\": \"user\", \"content\": comment_text},\n",
    "        ],\n",
    "        response_format=RelationClassification,\n",
    "        temperature=0,\n",
    "        top_p=1,\n",
    "    )\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_text_5ways(id: str, comment_text: str, argument: str, topic: str, samples: str) -> dict:\n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model='gpt-4o-mini',\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": f\"\"\"\n",
    "            Analyze the given comment about {topic} in relation to a specific argument. You need to:\n",
    "            Identify if the comment makes use of the given argument. Assign the following labels:\n",
    "            - 1 if the comment attacks the argument explicitly.\n",
    "            - 2 if the comment attacks the argument implicitly/vaguely.\n",
    "            - 4 if the comment supports the argument implicitly/vaguely.\n",
    "            - 5 if the comment supports the argument explicitly.\n",
    "            Do NOT use any other label.\n",
    "            Do NOT include the comment or the argument in the response.\n",
    "\n",
    "            Some examples:\n",
    "            {samples}\n",
    "            \n",
    "            The argument to analyze is: {argument}\n",
    "            \n",
    "            Provide your response in the following JSON format:\n",
    "            \n",
    "            {{\n",
    "                \"id\": \"{id}\",\n",
    "                \"label\": \"the label for the use of the argument in the comment\"\n",
    "            }}\n",
    "            \n",
    "            Analyze the following comment in relation to the given argument:\n",
    "            \"\"\"},\n",
    "            {\"role\": \"user\", \"content\": comment_text},\n",
    "        ],\n",
    "        response_format=RelationClassification,\n",
    "        temperature=0,\n",
    "        top_p=1,\n",
    "    )\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_comments_with_arguments(df: pd.DataFrame, output_file: str, topic: str, samples: str, detailed = False):\n",
    "    with jsonl.open(output_file, mode='w') as writer:\n",
    "        for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing comments\"):\n",
    "            comment_id = row['id']\n",
    "            comment_text = row['comment_text']\n",
    "            argument_text = row['argument_text']\n",
    "            if detailed == False:\n",
    "                model = classify_text_2ways\n",
    "            else:\n",
    "                model = classify_text_5ways\n",
    "            try:\n",
    "                gpt_response = model(comment_id, comment_text, argument_text, topic, samples)\n",
    "                classification = json.loads(gpt_response)\n",
    "                output_entry = {\"id\": comment_id, \"label\": classification[\"label\"]}\n",
    "                writer.write(output_entry)\n",
    "\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"JSONDecodeError for comment: {comment_text[:50]}... - Error: {e}\")\n",
    "                error_entry = {\"id\": comment_id, \"label\": 3}\n",
    "                writer.write(error_entry)\n",
    "                continue\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"An unexpected error occurred for comment: {comment_text[:50]}... - Error: {e}\")\n",
    "                error_entry = {\"id\": comment_id, \"label\": 3}\n",
    "                writer.write(error_entry)\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['108arg2']\n",
      "4\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing comments: 100%|██████████| 431/431 [07:01<00:00,  1.02it/s]\n"
     ]
    }
   ],
   "source": [
    "gm = pd.read_csv('/Users/guida/llm_argument_tasks/clean_data/GM_structured_main.csv')\n",
    "samples = prep_fewshot_samples_2ways('/Users/guida/llm_argument_tasks/clean_data/GM_structured_one_shot.csv', 1)\n",
    "process_comments_with_arguments(gm, 'comarg_gm_relation_identification2ways_gpt_1shot.jsonl', 'gay marriage', samples, detailed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['108arg2', '175arg4', '161arg4', '5arg5', '198arg5']\n",
      "1\n",
      "2\n",
      "1\n",
      "4\n",
      "5\n",
      "5\n",
      "4\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing comments: 100%|██████████| 431/431 [07:03<00:00,  1.02it/s]\n"
     ]
    }
   ],
   "source": [
    "gm = pd.read_csv('/Users/guida/llm_argument_tasks/clean_data/GM_structured_main.csv')\n",
    "samples = prep_fewshot_samples_2ways('/Users/guida/llm_argument_tasks/clean_data/GM_structured_shots.csv',5)\n",
    "process_comments_with_arguments(gm, 'comarg_gm_relation_identification2ways_gpt_5shot.jsonl', 'gay marriage', samples, detailed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['108arg2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing comments: 100%|██████████| 431/431 [07:11<00:00,  1.00s/it]\n"
     ]
    }
   ],
   "source": [
    "gm = pd.read_csv('/Users/guida/llm_argument_tasks/clean_data/GM_structured_main.csv')\n",
    "samples = prep_fewshot_samples_5ways('/Users/guida/llm_argument_tasks/clean_data/GM_structured_one_shot.csv',1)\n",
    "process_comments_with_arguments(gm, 'comarg_gm_relation_identification5ways_gpt_1shot.jsonl', 'gay marriage', samples, detailed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5arg5', '175arg4', '198arg5', '161arg4', '108arg2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing comments:   0%|          | 0/431 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing comments: 100%|██████████| 431/431 [07:19<00:00,  1.02s/it]\n"
     ]
    }
   ],
   "source": [
    "gm = pd.read_csv('/Users/guida/llm_argument_tasks/clean_data/GM_structured_main.csv')\n",
    "samples = prep_fewshot_samples_5ways('/Users/guida/llm_argument_tasks/clean_data/GM_structured_shots.csv',5)\n",
    "process_comments_with_arguments(gm, 'comarg_gm_relation_identification5ways_gpt_5shot.jsonl', 'gay marriage', samples, detailed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['414721757arg6']\n",
      "2\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing comments: 100%|██████████| 317/317 [05:45<00:00,  1.09s/it]\n"
     ]
    }
   ],
   "source": [
    "ugip = pd.read_csv('/Users/guida/llm_argument_tasks/clean_data/UGIP_structured_main.csv')\n",
    "samples = prep_fewshot_samples_2ways('/Users/guida/llm_argument_tasks/clean_data/UGIP_structured_one_shot.csv', 1)\n",
    "process_comments_with_arguments(ugip, 'comarg_ugip_relation_identification2ways_gpt_1shot.jsonl', 'whether \"Under God\" should appear in the US Pledge of Allegiance', samples, detailed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['414721922arg3', '414721727arg3', '414721757arg6', '414721831arg6', '414721738arg1']\n",
      "1\n",
      "2\n",
      "1\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing comments: 100%|██████████| 317/317 [05:31<00:00,  1.05s/it]\n"
     ]
    }
   ],
   "source": [
    "ugip = pd.read_csv('/Users/guida/llm_argument_tasks/clean_data/UGIP_structured_main.csv')\n",
    "samples = prep_fewshot_samples_2ways('/Users/guida/llm_argument_tasks/clean_data/UGIP_structured_shots.csv',5)\n",
    "process_comments_with_arguments(ugip, 'comarg_ugip_relation_identification2ways_gpt_5shot.jsonl', 'whether \"Under God\" should appear in the US Pledge of Allegiance', samples, detailed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['414721757arg6']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing comments:   0%|          | 0/317 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing comments: 100%|██████████| 317/317 [05:22<00:00,  1.02s/it]\n"
     ]
    }
   ],
   "source": [
    "ugip = pd.read_csv('/Users/guida/llm_argument_tasks/clean_data/UGIP_structured_main.csv')\n",
    "samples = prep_fewshot_samples_5ways('/Users/guida/llm_argument_tasks/clean_data/UGIP_structured_one_shot.csv',1)\n",
    "process_comments_with_arguments(ugip, 'comarg_ugip_relation_identification5ways_gpt_1shot.jsonl', 'whether \"Under God\" should appear in the US Pledge of Allegiance', samples, detailed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['414721727arg3', '414721922arg3', '414721738arg1', '414721757arg6', '414721831arg6']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing comments: 100%|██████████| 317/317 [05:39<00:00,  1.07s/it]\n"
     ]
    }
   ],
   "source": [
    "ugip = pd.read_csv('/Users/guida/llm_argument_tasks/clean_data/UGIP_structured_main.csv')\n",
    "samples = prep_fewshot_samples_5ways('/Users/guida/llm_argument_tasks/clean_data/UGIP_structured_shots.csv',5)\n",
    "process_comments_with_arguments(ugip, 'comarg_ugip_relation_identification5ways_gpt_5shot.jsonl', 'whether \"Under God\" should appear in the US Pledge of Allegiance', samples, detailed=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
