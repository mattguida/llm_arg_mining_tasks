{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "import pandas as pd\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from random import sample\n",
    "import jsonlines as jsonl\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('/Users/guida/llm_argument_tasks/.env')\n",
    "\n",
    "api_key = os.environ.get('OPENAI_API_KEY')\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArgumentSpan(BaseModel):\n",
    "    id: str = Field(description=\"The ID of the comment being analyzed\")    \n",
    "    span: str = Field(description=\"The span of text in the comment that makes use of the argument\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary for label-to-argument mappings for each topic\n",
    "topic_label_to_argument = {\n",
    "    \"abortion\": {\n",
    "        \"p-right\": \"Abortion is a womanâ€™s right.\",\n",
    "        \"p-rape\": \"Rape victims need it to be legal.\",\n",
    "        \"p-not_human\": \"A fetus is not a human yet, so it's okay to abort.\",\n",
    "        \"p-mother_danger\": \"Abortion should be allowed when a mother's life is in danger.\",\n",
    "        \"p-baby_ill_treatment\": \"Unwanted babies are ill-treated by parents and/or not always adopted.\",\n",
    "        \"p-birth_ctrl\": \"Birth control fails at times and abortion is one way to deal with it.\",\n",
    "        \"p-not_murder\": \"Abortion is not murder.\",\n",
    "        \"p-sick_mom\": \"Mother is not healthy/financially solvent.\",\n",
    "        \"p-other\": \"Others\",\n",
    "        \"c-adopt\": \"Put baby up for adoption.\",\n",
    "        \"c-kill\": \"Abortion kills a life.\",\n",
    "        \"c-baby_right\": \"An unborn baby is a human and has the right to live.\",\n",
    "        \"c-sex\": \"Be willing to have the baby if you have sex.\",\n",
    "        \"c-bad_4_mom\": \"Abortion is harmful for women.\",\n",
    "        \"c-other\": \"Others\"\n",
    "    },\n",
    "    \"gayRights\": {\n",
    "        \"p-normal\": \"Gay marriage is like any other marriage.\",\n",
    "        \"p-right_denied\": \"Gay people should have the same rights as straight people.\",\n",
    "        \"p-no_threat_for_child\": \"Gay parents can adopt and ensure a happy life for a baby.\",\n",
    "        \"p-born\": \"People are born gay.\",\n",
    "        \"p-religion\": \"Religion should not be used against gay rights.\",\n",
    "        \"p-Other\": \"Others\",\n",
    "        \"c-religion\": \"Religion does not permit gay marriages.\",\n",
    "        \"c-abnormal\": \"Gay marriages are not normal/against nature.\",\n",
    "        \"c-threat_to_child\": \"Gay parents cannot raise kids properly.\",\n",
    "        \"c-gay_problems\": \"Gay people have problems and create social issues.\",\n",
    "        \"c-Other\": \"Others\"\n",
    "    },\n",
    "    \"obama\": {\n",
    "        \"p-economy\": \"Fixed the economy.\",\n",
    "        \"p-War\": \"Ending the wars.\",\n",
    "        \"p-republicans\": \"Better than the republican candidates.\",\n",
    "        \"p-decision_policies\": \"Makes good decisions/policies.\",\n",
    "        \"p-quality\": \"Has qualities of a good leader.\",\n",
    "        \"p-health\": \"Ensured better healthcare.\",\n",
    "        \"p-foreign_policies\": \"Executed effective foreign policies.\",\n",
    "        \"p-job\": \"Created more jobs.\",\n",
    "        \"p-Other\": \"Others\",\n",
    "        \"c-economy\": \"Destroyed our economy.\",\n",
    "        \"c-War\": \"Wars are still on.\",\n",
    "        \"c-job\": \"Unemployment rate is high.\",\n",
    "        \"c-health\": \"Healthcare bill is a failure.\",\n",
    "        \"c-decision_policies\": \"Poor decision-maker.\",\n",
    "        \"c-republicans\": \"We have better republicans than Obama.\",\n",
    "        \"c-quality\": \"Not eligible as a leader.\",\n",
    "        \"c-foreign_policies\": \"Ineffective foreign policies.\",\n",
    "        \"c-Other\": \"Others\"\n",
    "    },\n",
    "    \"marijuana\": {\n",
    "        \"p-not_addictive\": \"Not addictive.\",\n",
    "        \"p-medicine\": \"Used as a medicine for its positive effects.\",\n",
    "        \"p-legal\": \"Legalized marijuana can be controlled and regulated by the government.\",\n",
    "        \"p-right\": \"Prohibition violates human rights.\",\n",
    "        \"p-no_damage\": \"Does not cause any damage to our bodies.\",\n",
    "        \"p-Other\": \"Others\",\n",
    "        \"c-health\": \"Damages our bodies.\",\n",
    "        \"c-mind\": \"Responsible for brain damage.\",\n",
    "        \"c-illegal\": \"If legalized, people will use marijuana and other drugs more.\",\n",
    "        \"c-crime\": \"Causes crime.\",\n",
    "        \"c-addiction\": \"Highly addictive.\",\n",
    "        \"c-Other\": \"Others\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_fewshot_samples(samples_file, topic, n):\n",
    "    df = pd.read_csv(samples_file)\n",
    "\n",
    "    if n !=5:\n",
    "        ids = df['id'].to_list()\n",
    "        sampled = sample(ids, n)\n",
    "        #print(sampled)\n",
    "        df = df[df['id'].isin(sampled)]\n",
    "    \n",
    "    output = ''\n",
    "    #print(output)\n",
    "    for i, row in df.iterrows():\n",
    "        comment = row['text']\n",
    "        output = f\"{output}\\n Comment: {comment}\\n\"\n",
    "        argument_type = row['label']\n",
    "        argument = topic_label_to_argument[topic][argument_type]\n",
    "        output = f\"{output} Argument {i}: {argument}\\n\"\n",
    "        span = row['line']\n",
    "        output = f\"{output} Span: {span}\\n\\n\"\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_text(id: str, comment_text: str, topic: str, argument_text: str, samples:str) -> dict:\n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": f\"\"\"\n",
    "            Analyze the given comment in relation to a specific argument about {topic}. You need to:\n",
    "            Identify the relevant span of text where the comment makes use of the given argument. \n",
    "            Provide the exact span of the text in the comment that makes use of the argument.\n",
    "            Only report the exact original fragment of text. Do NOT paraphrase. Do NOT include any additional text.\n",
    "\n",
    "            Some examples:\n",
    "            {samples}\n",
    "            \n",
    "            The argument to analyze is: {argument_text}\n",
    "            \n",
    "            Provide your response in the following JSON format:\n",
    "            \n",
    "            {{\n",
    "                \"id\": \"{id}\",\n",
    "                \"span\": \"the relevant span of text\"\n",
    "            }}\n",
    "            \n",
    "            Analyze the following comment in relation to the given argument:\n",
    "            \"\"\"},\n",
    "            {\"role\": \"user\", \"content\": comment_text},\n",
    "        ],\n",
    "        response_format=ArgumentSpan,\n",
    "        temperature=0,\n",
    "        top_p=1,\n",
    "    )\n",
    "    \n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataframe_comments(df: pd.DataFrame, topic: str, samples: str, n: int) -> List[dict]:\n",
    "    label_to_argument = topic_label_to_argument.get(topic, {}) \n",
    "    with jsonl.open(f'yru_{topic}_span_identification_gpt_{n}shot.jsonl', mode='a') as writer:\n",
    "        for idx, row in tqdm(df.iterrows(), desc=\"Processing comments\", unit=\"comment\", total=len(df)):\n",
    "            comment_id = row['id'] \n",
    "            comment_text = row['text']  \n",
    "            comment_label = row['label']  \n",
    "\n",
    "            argument_text = label_to_argument.get(comment_label)\n",
    "\n",
    "            try:\n",
    "                gpt_response = classify_text(\n",
    "                    id=comment_id,\n",
    "                    comment_text=comment_text,\n",
    "                    topic=topic,\n",
    "                    argument_text=argument_text,\n",
    "                    samples=samples\n",
    "                )\n",
    "                \n",
    "                classification = json.loads(gpt_response)\n",
    "                output_entry = {\"id\": comment_id, \"label\": classification[\"span\"]}\n",
    "                writer.write(output_entry)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"JSONDecodeError for comment: {comment_text[:50]}... - Error: {e}\")\n",
    "                error_entry = {\"id\": comment_id, \"span\": \"\"}\n",
    "                writer.write(error_entry)\n",
    "                continue\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"An unexpected error occurred for comment: {comment_text[:50]}... - Error: {e}\")\n",
    "                error_entry = {\"id\": comment_id, \"span\": \"\"}\n",
    "                writer.write(error_entry)\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing comments: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 686/686 [14:34<00:00,  1.27s/comment]\n"
     ]
    }
   ],
   "source": [
    "#topic = 'abortion'\n",
    "topic = 'marijuana'\n",
    "\n",
    "n = 5\n",
    "\n",
    "main_df = pd.read_csv(f'/Users/guida/llm_argument_tasks/clean_data/yru_{topic}_main.csv')\n",
    "\n",
    "samples = prep_fewshot_samples(f'/Users/guida/llm_argument_tasks/clean_data/yru_{topic}_shots.csv', topic, n)\n",
    "process_dataframe_comments(main_df, topic, samples, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing comments:   0%|          | 0/734 [00:00<?, ?comment/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing comments: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 734/734 [12:40<00:00,  1.04s/comment]\n"
     ]
    }
   ],
   "source": [
    "topic = 'abortion'\n",
    "\n",
    "n = 5\n",
    "\n",
    "main_df = pd.read_csv(f'/Users/guida/llm_argument_tasks/clean_data/yru_{topic}_main.csv')\n",
    "\n",
    "samples = prep_fewshot_samples(f'/Users/guida/llm_argument_tasks/clean_data/yru_{topic}_shots.csv', topic, n)\n",
    "process_dataframe_comments(main_df, topic, samples, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing comments:   0%|          | 0/641 [00:00<?, ?comment/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing comments: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 641/641 [13:30<00:00,  1.27s/comment]  \n"
     ]
    }
   ],
   "source": [
    "#topic = 'abortion'\n",
    "topic = 'obama'\n",
    "\n",
    "n = 5\n",
    "\n",
    "main_df = pd.read_csv(f'/Users/guida/llm_argument_tasks/clean_data/yru_{topic}_main.csv')\n",
    "\n",
    "samples = prep_fewshot_samples(f'/Users/guida/llm_argument_tasks/clean_data/yru_{topic}_shots.csv', topic, n)\n",
    "process_dataframe_comments(main_df, topic, samples, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing comments:   0%|          | 0/767 [00:00<?, ?comment/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing comments: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 767/767 [14:29<00:00,  1.13s/comment]\n"
     ]
    }
   ],
   "source": [
    "#topic = 'abortion'\n",
    "topic = 'gayRights'\n",
    "\n",
    "n = 5\n",
    "\n",
    "main_df = pd.read_csv(f'/Users/guida/llm_argument_tasks/clean_data/yru_{topic}_main.csv')\n",
    "\n",
    "samples = prep_fewshot_samples(f'/Users/guida/llm_argument_tasks/clean_data/yru_{topic}_shots.csv', topic, n)\n",
    "process_dataframe_comments(main_df, topic, samples, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing comments:   0%|          | 0/686 [00:00<?, ?comment/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing comments: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 686/686 [13:52<00:00,  1.21s/comment]\n"
     ]
    }
   ],
   "source": [
    "#topic = 'abortion'\n",
    "topic = 'marijuana'\n",
    "\n",
    "n = 1\n",
    "\n",
    "main_df = pd.read_csv(f'/Users/guida/llm_argument_tasks/clean_data/yru_{topic}_main.csv')\n",
    "\n",
    "samples = prep_fewshot_samples(f'/Users/guida/llm_argument_tasks/clean_data/yru_{topic}_shots.csv', topic, n)\n",
    "process_dataframe_comments(main_df, topic, samples, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing comments:   0%|          | 0/734 [00:00<?, ?comment/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing comments: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 734/734 [13:47<00:00,  1.13s/comment]\n"
     ]
    }
   ],
   "source": [
    "topic = 'abortion'\n",
    "\n",
    "n = 1\n",
    "\n",
    "main_df = pd.read_csv(f'/Users/guida/llm_argument_tasks/clean_data/yru_{topic}_main.csv')\n",
    "\n",
    "samples = prep_fewshot_samples(f'/Users/guida/llm_argument_tasks/clean_data/yru_{topic}_shots.csv', topic, n)\n",
    "process_dataframe_comments(main_df, topic, samples, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing comments:   0%|          | 0/641 [00:00<?, ?comment/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing comments: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 641/641 [12:15<00:00,  1.15s/comment]\n"
     ]
    }
   ],
   "source": [
    "#topic = 'abortion'\n",
    "topic = 'obama'\n",
    "\n",
    "n = 1\n",
    "\n",
    "main_df = pd.read_csv(f'/Users/guida/llm_argument_tasks/clean_data/yru_{topic}_main.csv')\n",
    "\n",
    "samples = prep_fewshot_samples(f'/Users/guida/llm_argument_tasks/clean_data/yru_{topic}_shots.csv', topic, n)\n",
    "process_dataframe_comments(main_df, topic, samples, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing comments:   0%|          | 0/767 [00:00<?, ?comment/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing comments: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 767/767 [14:19<00:00,  1.12s/comment] \n"
     ]
    }
   ],
   "source": [
    "#topic = 'abortion'\n",
    "topic = 'gayRights'\n",
    "\n",
    "n = 1\n",
    "\n",
    "main_df = pd.read_csv(f'/Users/guida/llm_argument_tasks/clean_data/yru_{topic}_main.csv')\n",
    "\n",
    "samples = prep_fewshot_samples(f'/Users/guida/llm_argument_tasks/clean_data/yru_{topic}_shots.csv', topic, n)\n",
    "process_dataframe_comments(main_df, topic, samples, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
